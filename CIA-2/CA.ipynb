{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f09fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed07eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer(n_in, n_out, act_func = None):\n",
    "    layer = {}\n",
    "    layer[\"weights\"] = np.random.random((n_out, n_in + 1))\n",
    "    if act_func:\n",
    "        layer[\"act_func\"] = act_func()\n",
    "    else:\n",
    "        layer[\"act_func\"] = None\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719016a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardpass_layer(layer, X):\n",
    "    X = np.concatenate((X, np.ones((X.shape[0], 1))), axis = 1)\n",
    "    if layer[\"act_func\"]:\n",
    "        temp = torch.tensor((X @ layer[\"weights\"].T).astype(np.float32))\n",
    "        return layer[\"act_func\"](temp).numpy()\n",
    "    else:\n",
    "        return X @ layer[\"weights\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e474517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(layers, act_funcs = None):\n",
    "    network = {}\n",
    "    network[\"layers\"] = []\n",
    "    network[\"layer_sizes\"] = []\n",
    "    \n",
    "    if act_funcs is None:\n",
    "        for i in range(len(layers) - 1):\n",
    "            network[\"layers\"] += [create_layer(layers[i], layers[i + 1])]\n",
    "            network[\"layer_sizes\"] += [(layers[i] + 1, layers[i + 1])]\n",
    "            \n",
    "    else:\n",
    "        for i in range(len(layers) - 1):\n",
    "            network[\"layers\"] += [create_layer(layers[i], layers[i + 1], act_funcs[i])]\n",
    "            network[\"layer_sizes\"] += [(layers[i] + 1, layers[i + 1])]\n",
    "            \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4061f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardpass_network(network, X):\n",
    "    for layer in network[\"layers\"]:\n",
    "        X = forwardpass_layer(layer, X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e105b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_vector(network):\n",
    "    weight_vector = []\n",
    "    \n",
    "    for layer in network[\"layers\"]:\n",
    "        weight_vector += [layer[\"weights\"].flatten()]\n",
    "        \n",
    "    weight_vector = np.concatenate(weight_vector)\n",
    "    return weight_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88413413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_layer_weights(network, weight_vector):\n",
    "    start = 0\n",
    "    \n",
    "    for l in range(len(network[\"layer_sizes\"])):\n",
    "        input_size, output_size = network[\"layer_sizes\"][l]\n",
    "        weights = weight_vector[start:start + input_size*output_size]\n",
    "        weights = weights.reshape((output_size, input_size))\n",
    "        network[\"layers\"][l][\"weights\"] = weights\n",
    "        start += input_size * output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f1eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_belief(ind_size, startMean, startStd):\n",
    "    belief = {}\n",
    "    belief[\"ind_size\"] = ind_size\n",
    "    \n",
    "    try:\n",
    "        _ = len(startMean)\n",
    "        belief[\"mean\"] = np.full(ind_size, startMean)\n",
    "        belief[\"std\"] = np.full(ind_size, startStd)\n",
    "        \n",
    "    except:\n",
    "        belief[\"mean\"] = startMean\n",
    "        belief[\"std\"] = startStd\n",
    "        \n",
    "    return belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4f35945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bel_generate_population(belief, pop_size):\n",
    "    belief[\"pop\"] = (belief[\"mean\"] + belief[\"std\"] * np.random.randn(pop_size, belief[\"ind_size\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b639ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_traits(belief):\n",
    "    temp = belief[\"pop\"].T\n",
    "    for i in range(len(temp)):\n",
    "        belief[\"mean\"] = np.mean(temp[i])\n",
    "        belief[\"std\"] = np.std(temp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d3ef495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ca(model, X, Y, beliefs, mut_rate = 1):\n",
    "    ca = {}\n",
    "    ca[\"model\"] = model\n",
    "    ca[\"X\"] = X\n",
    "    ca[\"Y\"] = Y\n",
    "    ca[\"mut_rate\"] = mut_rate\n",
    "    \n",
    "    ca[\"ind_size\"] = get_weight_vector(model).shape[0]\n",
    "    ca[\"cultures\"] = []\n",
    "    \n",
    "    for belief_params in beliefs:\n",
    "        ca[\"cultures\"] += [create_belief(ca[\"ind_size\"], belief_params[0], belief_params[1])]\n",
    "        \n",
    "    return ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e313b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(ca, pop_sizePerBelief):\n",
    "    ca[\"pop_sizePerBelief\"] = pop_sizePerBelief\n",
    "    ca[\"pop_size\"] = len(ca['cultures']) * pop_sizePerBelief\n",
    "    for belief in ca[\"cultures\"]:\n",
    "        bel_generate_population(belief, pop_sizePerBelief)\n",
    "        try:\n",
    "            ca[\"pop\"] = np.concatenate((ca[\"pop\"], belief[\"pop\"]))\n",
    "        except:\n",
    "            ca[\"pop\"] = belief[\"pop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2766836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_population_roulette(ca):\n",
    "    evaluate_population(ca)\n",
    "    temp = ca[\"pop\"].copy()\n",
    "    \n",
    "    for i in range(ca[\"pop_size\"]):\n",
    "        ca[\"scores\"] = ca[\"scores\"] / np.sum(ca[\"scores\"])\n",
    "\n",
    "        roulette = np.cumsum(ca[\"scores\"])\n",
    "\n",
    "        newPopIndex = []\n",
    "        for count in range(ca[\"pop_size\"]):\n",
    "            roulette_ball = np.random.random()\n",
    "            newPopIndex += [(roulette >= roulette_ball).tolist().index(True)]\n",
    "                \n",
    "    ca[\"pop\"] = temp[newPopIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c388d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_population(ca):\n",
    "    evaluate_population(ca)\n",
    "    \n",
    "    nextPopIndices = np.argsort(ca[\"scores\"])[::-1][:ca[\"pop_size\"]]\n",
    "    \n",
    "    ca[\"pop\"] = ca[\"pop\"][nextPopIndices]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "319173ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(ca, ind):\n",
    "    if np.random.random() > (1-ca[\"mut_rate\"]):\n",
    "        index = np.random.randint(ca[\"ind_size\"])\n",
    "        ind[index] = np.random.randint(100) * np.random.rand()\n",
    "        \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39e6e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_over(ca, p1, p2):\n",
    "    point = np.random.randint(ca[\"ind_size\"])\n",
    "    \n",
    "    off1 = np.concatenate((p1[:point], p2[point:]))\n",
    "    off2 = np.concatenate((p1[point:], p2[:point]))\n",
    "    \n",
    "    off1 = mutate(ca, off1)\n",
    "    off2 = mutate(ca, off2)\n",
    "    \n",
    "    return np.array([off1, off2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c588443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce(ca):\n",
    "    for p1 in range(ca[\"pop_size\"]):\n",
    "        for p2 in range(ca[\"pop_size\"]):\n",
    "            if p1 != p2:\n",
    "                ca[\"pop\"] = np.concatenate((ca[\"pop\"], cross_over(ca, ca[\"pop\"][p1], ca[\"pop\"][p2])))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3325efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(ca):\n",
    "    scores = []\n",
    "    for individual in ca[\"pop\"]:\n",
    "        set_layer_weights(ca[\"model\"], individual)\n",
    "        pred = np.round(forwardpass_network(ca[\"model\"], ca[\"X\"]))\n",
    "        scores += [accuracy_score(ca[\"Y\"], pred)]            \n",
    "    ca[\"scores\"] = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6a731f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(ca):\n",
    "    for belief in ca[\"cultures\"]:\n",
    "        z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n",
    "        newPopulationOfBelief = np.argsort(z)[:ca[\"pop_sizePerBelief\"]]\n",
    "        belief[\"pop\"] = ca[\"pop\"][newPopulationOfBelief]\n",
    "        ca[\"pop\"] = ca[\"pop\"][np.argsort(z)[ca[\"pop_sizePerBelief\"]:]]\n",
    "        \n",
    "        try:\n",
    "            temp = np.concatenate((belief[\"pop\"], temp))\n",
    "        except:\n",
    "            temp = belief[\"pop\"]\n",
    "            \n",
    "    for belief in ca[\"cultures\"]:\n",
    "        ca[\"pop\"] = np.concatenate((ca[\"pop\"], belief[\"pop\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c5107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beliefs(ca):\n",
    "    for belief in ca[\"cultures\"]:\n",
    "        update_traits(belief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3be146ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Bank_Personal_Loan_Modelling.csv\")\n",
    "data = data.drop([\"ID\", \"ZIP Code\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04f197c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Personal Loan\", axis = 1).values\n",
    "y = data[\"Personal Loan\"].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09d85275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e392c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e524c263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  :  0.803\n",
      "epoch :  1  :  0.9045\n",
      "epoch :  2  :  0.9045\n",
      "epoch :  3  :  0.9045\n",
      "epoch :  4  :  0.9045\n",
      "epoch :  5  :  0.9045\n",
      "epoch :  6  :  0.9045\n",
      "epoch :  7  :  0.9045\n",
      "epoch :  8  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  9  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  10  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  11  :  0.9045\n",
      "epoch :  12  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  13  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  14  :  0.9045\n",
      "epoch :  15  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  16  :  0.9045\n",
      "epoch :  17  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  18  :  0.9045\n",
      "epoch :  19  :  0.9045\n",
      "epoch :  20  :  0.9045\n",
      "epoch :  21  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  22  :  0.9045\n",
      "epoch :  23  :  0.9045\n",
      "epoch :  24  :  0.9045\n",
      "epoch :  25  :  0.9045\n",
      "epoch :  26  :  0.9045\n",
      "epoch :  27  :  0.9045\n",
      "epoch :  28  :  0.9045\n",
      "epoch :  29  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  30  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  31  :  0.9045\n",
      "epoch :  32  :  0.9045\n",
      "epoch :  33  :  0.9045\n",
      "epoch :  34  :  0.9045\n",
      "epoch :  35  :  0.9045\n",
      "epoch :  36  :  0.9045\n",
      "epoch :  37  :  0.9045\n",
      "epoch :  38  :  0.9045\n",
      "epoch :  39  :  0.9045\n",
      "epoch :  40  :  0.9045\n",
      "epoch :  41  :  0.9045\n",
      "epoch :  42  :  0.9045\n",
      "epoch :  43  :  0.9045\n",
      "epoch :  44  :  0.9045\n",
      "epoch :  45  :  0.9045\n",
      "epoch :  46  :  0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Temp\\ipykernel_25204\\924963958.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z = np.sum((ca[\"pop\"] - belief[\"mean\"]), axis = 1) / (belief[\"std\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  47  :  0.9045\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):    \n\u001b[0;32m     11\u001b[0m     reproduce(ca)\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mselect_next_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     classify(ca)\n\u001b[0;32m     14\u001b[0m     update_beliefs(ca)\n",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m, in \u001b[0;36mselect_next_population\u001b[1;34m(ca)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_next_population\u001b[39m(ca):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mevaluate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     nextPopIndices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(ca[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m])[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:ca[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpop_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      6\u001b[0m     ca[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ca[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpop\u001b[39m\u001b[38;5;124m\"\u001b[39m][nextPopIndices]\n",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m, in \u001b[0;36mevaluate_population\u001b[1;34m(ca)\u001b[0m\n\u001b[0;32m      4\u001b[0m     set_layer_weights(ca[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], individual)\n\u001b[0;32m      5\u001b[0m     pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(forwardpass_network(ca[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], ca[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m----> 6\u001b[0m     scores \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mca\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m]            \n\u001b[0;32m      7\u001b[0m ca[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:88\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     86\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m     87\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 88\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_pred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py:363\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n\u001b[0;32m    362\u001b[0m first_row \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\u001b[38;5;241m.\u001b[39mgetrow(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:84\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    270\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:333\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    331\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    335\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = create_network([11, 4, 1], [nn.Sigmoid, nn.Sigmoid])\n",
    "forwardpass_network(model, X_train)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "ca = create_ca(model, X_train, y_train, [(20, 20),(10,10),(100, 10)], 1)\n",
    "generate_population(ca, 10)\n",
    "\n",
    "acc = 0\n",
    "for epoch in range(epochs):    \n",
    "    reproduce(ca)\n",
    "    select_next_population(ca)\n",
    "    classify(ca)\n",
    "    update_beliefs(ca)\n",
    "    evaluate_population(ca)\n",
    "    acc = max(ca[\"scores\"])\n",
    "    print(\"epoch : \",epoch,\" : \",acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
