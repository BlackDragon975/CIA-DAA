{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7810c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26861d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer(n_in, n_out, act_func = None):\n",
    "    layer = {}\n",
    "    \n",
    "    layer[\"weights\"] = np.random.random((n_out, n_in + 1))\n",
    "    layer[\"act_func\"] = act_func()\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2c3eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_layer(layer, X):\n",
    "    X = np.concatenate((X, np.ones((X.shape[0], 1))), axis = 1)\n",
    "\n",
    "    temp = torch.tensor((X @ layer[\"weights\"].T).astype(np.float32))\n",
    "    return layer[\"act_func\"](temp).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a3d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(layers, act_funcs):\n",
    "    network = {}\n",
    "    network[\"layers\"] = []\n",
    "    network[\"layer_sizes\"] = []\n",
    "\n",
    "    for i in range(len(layers) - 1):\n",
    "        network[\"layers\"] += [create_layer(layers[i], layers[i + 1], act_funcs[i])]\n",
    "        network[\"layer_sizes\"] += [(layers[i] + 1, layers[i + 1])]\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e63fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_network(network, X):\n",
    "    for layer in network[\"layers\"]:\n",
    "        X = pass_layer(layer, X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d17b58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_vector(network):\n",
    "    weight_vector = []\n",
    "    \n",
    "    for layer in network[\"layers\"]:\n",
    "        weight_vector += [layer[\"weights\"].flatten()]\n",
    "        \n",
    "    weight_vector = np.concatenate(weight_vector)\n",
    "    return weight_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0ae16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_layer_weights(network, weight_vector):\n",
    "    start = 0\n",
    "    \n",
    "    for l in range(len(network[\"layer_sizes\"])):\n",
    "        input_size, output_size = network[\"layer_sizes\"][l]\n",
    "        weights = weight_vector[start:start + input_size*output_size]\n",
    "        weights = weights.reshape((output_size, input_size))\n",
    "        network[\"layers\"][l][\"weights\"] = weights\n",
    "        start += input_size * output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "044d653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aco(model, X, Y):\n",
    "    aco = {}\n",
    "    aco[\"model\"] = model\n",
    "    aco[\"X\"] = X\n",
    "    aco[\"Y\"] = Y\n",
    "    aco[\"ind_size\"] = get_weight_vector(model).shape[0]\n",
    "    return aco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e95405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_batch(aco, pop_size):\n",
    "    aco[\"pop_size\"] = pop_size\n",
    "    means, stds = np.random.randint(100,  size = pop_size), np.random.randint(100,  size = pop_size)\n",
    "    \n",
    "    aco[\"ant\"] = []\n",
    "    \n",
    "    for i in range(pop_size):\n",
    "        aco[\"ant\"] += [means[i] + stds[i] * np.random.randn(aco[\"ind_size\"])]\n",
    "    aco[\"ant\"] = np.array(aco[\"ant\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeae1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(aco):\n",
    "    scores = []\n",
    "    for ant in aco[\"ant\"]:\n",
    "        set_layer_weights(aco[\"model\"], ant)\n",
    "        pred = np.round(pass_network(aco[\"model\"], aco[\"X\"]))\n",
    "        scores += [accuracy_score(aco[\"Y\"], pred)]\n",
    "    \n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143388d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pher_calc(aco):\n",
    "    scores = evaluate(aco)\n",
    "    aco[\"pher\"] = scores / sum(scores)\n",
    "    aco[\"std\"] = 1 / scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c3de0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(prob):\n",
    "    total = np.cumsum(prob)\n",
    "    choice = np.random.random()\n",
    "    \n",
    "    return np.where(total >= choice)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc35280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(aco):\n",
    "    next_batch = []\n",
    "    \n",
    "    for i in range(aco[\"pop_size\"]):\n",
    "        next_batch += [[0 for i in range(aco[\"ind_size\"])]]\n",
    "        \n",
    "        for j in range(aco[\"ind_size\"]):\n",
    "            next_ant = select(aco[\"pher\"])\n",
    "            \n",
    "            next_batch[i][j] = aco[\"ant\"][next_ant][j] + aco[\"std\"][next_ant] * np.random.randn()\n",
    "            \n",
    "    next_batch = np.array(next_batch)\n",
    "    aco[\"ant\"] = next_batch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25482ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Bank_Personal_Loan_Modelling.csv\")\n",
    "data = data.drop([\"ID\", \"ZIP Code\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d0dae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Personal Loan\", axis = 1)\n",
    "y = data[\"Personal Loan\"].values\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c27aab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db9163aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8473c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9223066 ],\n",
       "       [0.9403717 ],\n",
       "       [0.8396028 ],\n",
       "       ...,\n",
       "       [0.77922946],\n",
       "       [0.87868464],\n",
       "       [0.8794223 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_network([11, 4, 1], [nn.Sigmoid, nn.Sigmoid])\n",
    "pass_network(model, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5034a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "aco = create_aco(model, X_train, y_train)\n",
    "\n",
    "first_batch(aco, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "750cfe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0  :  0.904\n",
      "epoch : 1  :  0.904\n",
      "epoch : 2  :  0.904\n",
      "epoch : 3  :  0.904\n",
      "epoch : 4  :  0.904\n",
      "epoch : 5  :  0.904\n",
      "epoch : 6  :  0.904\n",
      "epoch : 7  :  0.904\n",
      "epoch : 8  :  0.904\n",
      "epoch : 9  :  0.904\n",
      "epoch : 10  :  0.904\n",
      "epoch : 11  :  0.904\n",
      "epoch : 12  :  0.904\n",
      "epoch : 13  :  0.904\n",
      "epoch : 14  :  0.904\n",
      "epoch : 15  :  0.904\n",
      "epoch : 16  :  0.904\n",
      "epoch : 17  :  0.904\n",
      "epoch : 18  :  0.904\n",
      "epoch : 19  :  0.904\n",
      "epoch : 20  :  0.904\n",
      "epoch : 21  :  0.904\n",
      "epoch : 22  :  0.904\n",
      "epoch : 23  :  0.904\n",
      "epoch : 24  :  0.904\n",
      "epoch : 25  :  0.904\n",
      "epoch : 26  :  0.904\n",
      "epoch : 27  :  0.904\n",
      "epoch : 28  :  0.904\n",
      "epoch : 29  :  0.904\n",
      "epoch : 30  :  0.904\n",
      "epoch : 31  :  0.904\n",
      "epoch : 32  :  0.904\n",
      "epoch : 33  :  0.904\n",
      "epoch : 34  :  0.904\n",
      "epoch : 35  :  0.904\n",
      "epoch : 36  :  0.904\n",
      "epoch : 37  :  0.904\n",
      "epoch : 38  :  0.904\n",
      "epoch : 39  :  0.904\n",
      "epoch : 40  :  0.904\n",
      "epoch : 41  :  0.90425\n",
      "epoch : 42  :  0.904\n",
      "epoch : 43  :  0.904\n",
      "epoch : 44  :  0.904\n",
      "epoch : 45  :  0.904\n",
      "epoch : 46  :  0.904\n",
      "epoch : 47  :  0.904\n",
      "epoch : 48  :  0.904\n",
      "epoch : 49  :  0.904\n",
      "epoch : 50  :  0.904\n",
      "epoch : 51  :  0.904\n",
      "epoch : 52  :  0.904\n",
      "epoch : 53  :  0.904\n",
      "epoch : 54  :  0.904\n",
      "epoch : 55  :  0.904\n",
      "epoch : 56  :  0.904\n",
      "epoch : 57  :  0.904\n",
      "epoch : 58  :  0.904\n",
      "epoch : 59  :  0.904\n",
      "epoch : 60  :  0.904\n",
      "epoch : 61  :  0.904\n",
      "epoch : 62  :  0.904\n",
      "epoch : 63  :  0.90425\n",
      "epoch : 64  :  0.904\n",
      "epoch : 65  :  0.90475\n",
      "epoch : 66  :  0.904\n",
      "epoch : 67  :  0.90425\n",
      "epoch : 68  :  0.904\n",
      "epoch : 69  :  0.904\n",
      "epoch : 70  :  0.904\n",
      "epoch : 71  :  0.904\n",
      "epoch : 72  :  0.904\n",
      "epoch : 73  :  0.904\n",
      "epoch : 74  :  0.904\n",
      "epoch : 75  :  0.904\n",
      "epoch : 76  :  0.904\n",
      "epoch : 77  :  0.904\n",
      "epoch : 78  :  0.904\n",
      "epoch : 79  :  0.904\n",
      "epoch : 80  :  0.904\n",
      "epoch : 81  :  0.904\n",
      "epoch : 82  :  0.904\n",
      "epoch : 83  :  0.904\n",
      "epoch : 84  :  0.904\n",
      "epoch : 85  :  0.904\n",
      "epoch : 86  :  0.904\n",
      "epoch : 87  :  0.904\n",
      "epoch : 88  :  0.904\n",
      "epoch : 89  :  0.904\n",
      "epoch : 90  :  0.904\n",
      "epoch : 91  :  0.904\n",
      "epoch : 92  :  0.904\n",
      "epoch : 93  :  0.904\n",
      "epoch : 94  :  0.904\n",
      "epoch : 95  :  0.904\n",
      "epoch : 96  :  0.904\n",
      "epoch : 97  :  0.904\n",
      "epoch : 98  :  0.904\n",
      "epoch : 99  :  0.904\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    pher_calc(aco)\n",
    "    next_batch(aco)\n",
    "    \n",
    "    l = max(evaluate(aco))\n",
    "    print(f\"epoch : {epoch}  :  {l}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
